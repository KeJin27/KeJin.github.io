<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="author" content="Ke Jin">
  <meta name="description" content="Ke Jin's Homepage">
  <meta name="keywords" content="Ke Jin,金柯,homepage,主页,PhD,computer vision, Embodied AI, Zhejiang University">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ke Jin (金柯)'s Homepage</title>
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ke Jin (金柯)</name>
              </p>
              <p style="text-align:center">
                <a href="jk1206514673@gmail.com">Email</a> &nbsp; &nbsp;
		&nbsp;&nbsp; 
		<a href="https://scholar.google.com/citations?user=N3F3H0sAAAAJ&hl=en">Google Scholar</a> &nbsp; &nbsp;
		&nbsp;&nbsp;
		<a href="https://github.com/KeJin27">Github</a>
              </p>
              <p> I am a first-year PhD student supervised by <a href="https://perple-zju.github.io/">Qi Ye</a> in Zhejiang University. Prior to that, I obtained my Bachelor’s degree from Southeast University in 2024.
              </p>
              <p>
               My current research interest lies in 3D computer vision and Embodied AI, particularly in correspondence learning, pose estimation and dexterous manipulation.
              </p>
            </td>
            <td style="padding:15% 7% 7% 7%;width:40%;max-width:40%">
              <a href="images/JK.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JK.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; margin-top: -25px; "><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr></tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <div class="one">
                <img src='images/LightVisionCLIP.jpg' style="width:200%;max-width:100%; position: absolute;top: -5%">
                </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
                <papertitle>CLIP for Lightweight Semantic Segmentation</papertitle>
                <br>
                <strong>Ke Jin</strong>, Wankou Yang
                <br>
                <em>The 6th Chinese Conference on Pattern Recognition and Computer Vision</em>, PRCV 2025,
                <br>
                <a href="https://link.springer.com/chapter/10.1007/978-981-99-8549-4_27">[Paper]</a>
                <br>
                <p>We propose a feature fusion module to make language-guided lightweight semantic segmentation practical.</p>
            </td>
        </tr>	

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
		<video playsinline autoplay loop preload muted style="width:100%;max-width:100%; position: absolute;top: -5%">
                <source src='images/cogact.mp4'>
		</video>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>CogACT: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation</papertitle>
                <br>
                Qixiu Li, Yaobo Liang, Zeyu Wang, Lin Luo, Xi Chen, Mozheng Liao, Fangyun Wei, <strong>Yu Deng</strong>, Sicheng Xu, Yizhong Zhang, Xiaofan Wang, Bei Liu, Jianlong Fu, Jianmin Bao, Dong Chen, Yuanchun Shi, Jiaolong Yang, Baining Guo
                <br>
                <em>arXiv 2024</em>,
                <br>
                <a href="https://arxiv.org/abs/2411.19650">[PDF]</a>
                <a href="https://cogact.github.io/">[Project]</a>
		<a href="https://github.com/microsoft/CogACT">[Code]</a>
                <br>
                <p>We propose a new advanced VLA architecture for robot manipulation, which leverages cognitive information extracted by powerful VLMs to guide action prediction of a specialized action module.</p>
            </td>
        </tr>	

      </td>
    </tr>
  </table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Academic Services</heading>
    </td> 
  </tr>
</tbody>
</table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <td style="padding:20px;width:75%;vertical-align:middle">
      <strong>Conference Reviewer:</strong> ICCV
      <br>
      <strong>Journal Reviewer:</strong> 

  </td>
</tbody>
</table>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="width:0%;vertical-align:middle">
        </td>
        <td style="width:100%;vertical-align:middle">
        <hr style="margin-top:0px">
            <p><font color="#999999">The website template was adapted from <a href="https://jonbarron.info/">Jon Barron</a>.</font></p>
        </td>
    </tr>
  </tbody>
</table>
</body>

</html>
